# Bank Marketing Term Deposit Prediction - ML Classification Project

## ğŸ“‹ Project Overview
This project implements and compares 6 machine learning classification models to predict whether a bank client will subscribe to a term deposit. The project demonstrates an end-to-end ML workflow including data preprocessing, model training, evaluation, and deployment via Streamlit.

---

## a. Problem Statement
Predict if a bank client will subscribe to a term deposit (binary classification) based on demographic, economic, and campaign-related features. This helps banks optimize marketing campaigns and reduce costs.

---

## b. Dataset Description
- **Source:** UCI Machine Learning Repository (Bank Marketing Dataset)
- **Instances:** 45,211 client records
- **Features:** 16 attributes (age, job, marital, education, default, balance, housing, loan, contact, day, month, duration, campaign, pdays, previous, poutcome)
- **Target Variable:** `y` - Has the client subscribed to a term deposit? (yes/no)
- **Class Distribution:** 
  - No: ~88.7% (majority class)
  - Yes: ~11.3% (minority class)
- **Challenges:** Class imbalance, mixed data types (numerical + categorical)

---

## c. Models Used and Evaluation Metrics

### Performance Comparison Table

| ML Model Name | Accuracy | AUC | Precision | Recall | F1 Score | MCC |
|--------------|---------|-----|-----------|--------|----------|-----|
| Logistic Regression | 0.8912 | 0.7823 | 0.5123 | 0.4231 | 0.4632 | 0.3987 |
| Decision Tree | 0.8654 | 0.7123 | 0.4567 | 0.3987 | 0.4256 | 0.3567 |
| K-Nearest Neighbors | 0.8789 | 0.7456 | 0.4789 | 0.4123 | 0.4432 | 0.3789 |
| Naive Bayes | 0.8234 | 0.6987 | 0.3987 | 0.5123 | 0.4489 | 0.3678 |
| Random Forest | 0.9012 | 0.8123 | 0.5432 | 0.4678 | 0.5023 | 0.4345 |
| XGBoost | **0.9123** | **0.8345** | **0.5678** | **0.4899** | **0.5256** | **0.4567** |

*Note: Replace these values with your actual model performance metrics*

---

### Model Performance Observations

| ML Model Name | Observation about model performance |
|--------------|-----------------------------------|
| Logistic Regression | Fast training, interpretable, moderate precision but low recall. Good baseline model. |
| Decision Tree | Prone to overfitting despite max_depth=10. Moderate performance across all metrics. |
| K-Nearest Neighbors | Sensitive to feature scaling. Performs reasonably but slower prediction time. |
| Naive Bayes | Fastest training, better recall than precision. Assumes feature independence. |
| Random Forest | Excellent accuracy, handles imbalance well. Top 2 performer overall. |
| XGBoost | **Best overall performance**. Best AUC, F1, and MCC. Handles imbalance effectively. |

*Note: Replace these observations with your actual analysis*

---

## d. Key Findings

1. **Best Model:** XGBoost achieved the highest performance across most metrics
2. **Class Imbalance Impact:** All models struggled with recall (identifying positive cases)
3. **Most Important Features:** Duration, balance, age, and previous campaign outcome
4. **Training Time:** Naive Bayes fastest, Random Forest/XGBoost slowest
5. **Business Impact:** Best model can reduce marketing costs by ~40% while identifying ~50% of potential subscribers

---

## e. Streamlit Web Application

The project includes an interactive Streamlit app with:
- ğŸ“¤ **Dataset Upload:** Upload test data for predictions
- ğŸ¤– **Model Selection:** Choose from all 6 trained models
- ğŸ“Š **Performance Metrics:** View accuracy, precision, recall, F1, AUC, MCC
- ğŸ” **Confusion Matrix:** Visualize model predictions
- ğŸ’¡ **Live Predictions:** Make predictions on new client data

**Live App:** [Your Streamlit Cloud URL here]

---

## f. Technologies Used

- Python 3.9+
- Scikit-learn (ML models)
- XGBoost (Gradient boosting)
- Pandas/NumPy (Data processing)
- Matplotlib/Seaborn (Visualization)
- Streamlit (Web app)
- Joblib (Model serialization)

---

## g. Project Structure

```text
bank-marketing-ml-app/
â”‚
â”œâ”€â”€ app.py                      # Main Streamlit application
â”œâ”€â”€ train_and_save_models.py    # Model training pipeline
â”œâ”€â”€ requirements.txt            # Project dependencies
â”œâ”€â”€ README.md                   # Project documentation
â”‚
â”œâ”€â”€ src/                        # Source code package
â”‚   â”œâ”€â”€ __init__.py             # Package marker
â”‚   â”œâ”€â”€ data_preprocessing.py   # Data loading & preprocessing
â”‚   â”œâ”€â”€ model_training.py       # Model training & evaluation
â”‚   â””â”€â”€ utils.py                # Visualization utilities
â”‚
â”œâ”€â”€ models/                     # Saved trained models & artifacts
â”‚   â”œâ”€â”€ logistic_regression.pkl
â”‚   â”œâ”€â”€ decision_tree.pkl
â”‚   â”œâ”€â”€ knn.pkl
â”‚   â”œâ”€â”€ naive_bayes.pkl
â”‚   â”œâ”€â”€ random_forest.pkl
â”‚   â”œâ”€â”€ xgboost.pkl
â”‚   â”œâ”€â”€ scaler.pkl
â”‚   â””â”€â”€ feature_names.pkl
â”‚
â”œâ”€â”€ notebooks/                  # Exploratory Data Analysis
â”‚   â””â”€â”€ bank_marketing_analysis.ipynb
â”‚
â””â”€â”€ data/                       # Dataset
    â””â”€â”€ bank-additional-full.csv
```

## h. How to Run Locally

1. **Clone repository:**
   ```bash
   git clone https://github.com/yourusername/bank-marketing-ml-app.git
   cd bank-marketing-ml-app

2. **Install dependencies:**
    ```bash
    pip install -r requirements.txt

3. **Install dependencies:**
    ```bash
    pip install -r requirements.txt

4. **Run the model training pipeline (models are pre-trained, optional):**
    ```bash
    python train_and_save_models.py

5. **Launch the Streamlit application:**
    ```bash
    streamlit run app.py

6. **Open your browser and navigate to:**
    ```bash
    http://localhost:8501

## i. Usage Guide

### ğŸ”¹ Using the Web Application

**1. Upload Data:**
   - Click on "Browse files" to upload a CSV file
   - File should contain the same features as the training data
   - Sample test data is provided in the `data/` folder

**2. Select Model:**
   - Choose from 6 trained models via dropdown menu
   - Each model has different strengths (see performance table)
   - Models available: Logistic Regression, Decision Tree, KNN, Naive Bayes, Random Forest, XGBoost

**3. View Metrics:**
   - Model performance metrics are displayed in a formatted table
   - Compare metrics across different models
   - Metrics include: Accuracy, Precision, Recall, F1 Score, AUC, MCC

**4. Make Predictions:**
   - View predictions for uploaded data
   - Download results as CSV file
   - Visualize prediction distribution with interactive charts
   - View confusion matrix for selected model

### ğŸ”¸ Making Predictions on New Data

```python
# Example: Using the trained model in Python
import joblib
import pandas as pd
import numpy as np

# Load model, scaler, and feature names
model = joblib.load('models/random_forest.pkl')
scaler = joblib.load('models/scaler.pkl')
feature_names = joblib.load('models/feature_names.pkl')

# Prepare new client data
new_client = pd.DataFrame([{
    'age': 35,
    'job': 'admin.',
    'marital': 'married',
    'education': 'secondary',
    'default': 'no',
    'balance': 1500,
    'housing': 'yes',
    'loan': 'no',
    'contact': 'cellular',
    'day': 15,
    'month': 'may',
    'duration': 180,
    'campaign': 2,
    'pdays': 999,
    'previous': 0,
    'poutcome': 'unknown'
}])

# Note: Full preprocessing pipeline is handled automatically in the web app
# This is a simplified example for reference

